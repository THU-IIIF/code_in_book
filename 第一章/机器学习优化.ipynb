{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7f60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autogluon.core import TabularDataset\n",
    "# import numpy as np\n",
    "# from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# # from config import DATA_DIR\n",
    "# from engine.engine_utils import load_data\n",
    "\n",
    "# fields = ['shift(close,-1)/close -1', 'roc(close,20)', 'corr(close/shift(close,1), log(volume/shift(volume, 1)+1), 30)']\n",
    "# names = ['label_c', 'roc_20', 'CORR30']\n",
    "# symbols = ['510300.SH']\n",
    "\n",
    "# df = load_data(fields, names, symbols, columns=None, start_date='20100101',\n",
    "#                path=DATA_DIR.joinpath('etfs').resolve())\n",
    "\n",
    "# df['label'] = np.where(df['label_c'] > 0.0, 1, 0)\n",
    "# print(df['label'].value_counts())\n",
    "# del df['label_c']\n",
    "\n",
    "# split = int(len(df) * 0.8)\n",
    "# train = df.iloc[:split].copy()\n",
    "# test = df.iloc[split:].copy()\n",
    "# print('测试集日期', test.index[0])\n",
    "\n",
    "# label = 'label'\n",
    "# train_data = TabularDataset(train)\n",
    "# test_data = TabularDataset(test)\n",
    "\n",
    "# predictor = TabularPredictor(label=label, path='mymodel').fit(train_data)\n",
    "# print(predictor.leaderboard(test_data, silent=True))\n",
    "# y_pred = predictor.predict(test.drop(columns=[label]))\n",
    "# print(y_pred)\n",
    "# y_pred.to_csv('y_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45e85bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231023_023731/\"\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231023_023731/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #96~20.04.1-Ubuntu SMP Thu Sep 21 13:23:37 UTC 2023\n",
      "Disk Space Avail:   7232.98 GB / 7937.30 GB (91.1%)\n",
      "Train Data Rows:    39073\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43228.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.92 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.0639828014229775, Train Rows: 36573, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 119.87s of the 119.86s of remaining time.\n",
      "\t0.7752\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 119.8s of the 119.8s of remaining time.\n",
      "\t0.766\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 119.75s of the 119.75s of remaining time.\n",
      "\t0.8792\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 119.06s of the 119.06s of remaining time.\n",
      "\t0.8824\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 118.71s of the 118.71s of remaining time.\n",
      "\t0.8612\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 117.92s of the 117.92s of remaining time.\n",
      "\t0.8584\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 117.13s of the 117.13s of remaining time.\n",
      "\t0.8864\t = Validation score   (accuracy)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 113.87s of the 113.87s of remaining time.\n",
      "\t0.8528\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 113.06s of the 113.06s of remaining time.\n",
      "\t0.8524\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 112.28s of the 112.28s of remaining time.\n",
      "No improvement since epoch 9: early stopping\n",
      "\t0.8636\t = Validation score   (accuracy)\n",
      "\t15.25s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 96.99s of the 96.99s of remaining time.\n",
      "\t0.8872\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 96.29s of the 96.29s of remaining time.\n",
      "\t0.8584\t = Validation score   (accuracy)\n",
      "\t16.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 79.62s of the 79.62s of remaining time.\n",
      "\t0.8856\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.87s of the 78.75s of remaining time.\n",
      "\t0.8912\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 41.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231023_023731/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0               XGBoost    0.877162     0.8872        0.038864       0.028366   0.661730                 0.038864                0.028366           0.661730            1       True         11\n",
      "1   WeightedEnsemble_L2    0.876344     0.8912        0.180379       0.081010   3.062064                 0.001733                0.001742           0.510682            2       True         14\n",
      "2              CatBoost    0.875320     0.8864        0.009802       0.005365   3.251698                 0.009802                0.005365           3.251698            1       True          7\n",
      "3         LightGBMLarge    0.873784     0.8856        0.033295       0.008739   0.836131                 0.033295                0.008739           0.836131            1       True         13\n",
      "4              LightGBM    0.873477     0.8824        0.015478       0.006899   0.343505                 0.015478                0.006899           0.343505            1       True          4\n",
      "5            LightGBMXT    0.871430     0.8792        0.032820       0.009035   0.671972                 0.032820                0.009035           0.671972            1       True          3\n",
      "6      RandomForestGini    0.859351     0.8612        0.171715       0.050751   0.588709                 0.171715                0.050751           0.588709            1       True          5\n",
      "7        NeuralNetTorch    0.859044     0.8584        0.021528       0.010361  16.629256                 0.021528                0.010361          16.629256            1       True         12\n",
      "8      RandomForestEntr    0.857611     0.8584        0.140409       0.049410   0.598262                 0.140409                0.049410           0.598262            1       True          6\n",
      "9       NeuralNetFastAI    0.856485     0.8636        0.070515       0.021800  15.249409                 0.070515                0.021800          15.249409            1       True         10\n",
      "10       ExtraTreesGini    0.853414     0.8528        0.153458       0.051717   0.538761                 0.153458                0.051717           0.538761            1       True          8\n",
      "11       ExtraTreesEntr    0.850650     0.8524        0.190824       0.048388   0.515351                 0.190824                0.048388           0.515351            1       True          9\n",
      "12       KNeighborsUnif    0.773467     0.7752        0.058189       0.026229   0.038044                 0.058189                0.026229           0.038044            1       True          1\n",
      "13       KNeighborsDist    0.762719     0.7660        0.084994       0.015142   0.033336                 0.084994                0.015142           0.033336            1       True          2\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "predictor = TabularPredictor(label='class').fit(train_data, time_limit=120)  # Fit models for 120s\n",
    "leaderboard = predictor.leaderboard(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd53838c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.877162</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.028366</td>\n",
       "      <td>0.661730</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.028366</td>\n",
       "      <td>0.661730</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.180379</td>\n",
       "      <td>0.081010</td>\n",
       "      <td>3.062064</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.875320</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>3.251698</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>3.251698</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.873784</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.836131</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.836131</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.873477</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.343505</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.343505</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.871430</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.032820</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.671972</td>\n",
       "      <td>0.032820</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.671972</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.859351</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.171715</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.588709</td>\n",
       "      <td>0.171715</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.588709</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.859044</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>16.629256</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>16.629256</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.857611</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.140409</td>\n",
       "      <td>0.049410</td>\n",
       "      <td>0.598262</td>\n",
       "      <td>0.140409</td>\n",
       "      <td>0.049410</td>\n",
       "      <td>0.598262</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.856485</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>15.249409</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>15.249409</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>0.051717</td>\n",
       "      <td>0.538761</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>0.051717</td>\n",
       "      <td>0.538761</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.850650</td>\n",
       "      <td>0.8524</td>\n",
       "      <td>0.190824</td>\n",
       "      <td>0.048388</td>\n",
       "      <td>0.515351</td>\n",
       "      <td>0.190824</td>\n",
       "      <td>0.048388</td>\n",
       "      <td>0.515351</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.773467</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.058189</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.038044</td>\n",
       "      <td>0.058189</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.038044</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.762719</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.084994</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.084994</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0               XGBoost    0.877162     0.8872        0.038864       0.028366   \n",
       "1   WeightedEnsemble_L2    0.876344     0.8912        0.180379       0.081010   \n",
       "2              CatBoost    0.875320     0.8864        0.009802       0.005365   \n",
       "3         LightGBMLarge    0.873784     0.8856        0.033295       0.008739   \n",
       "4              LightGBM    0.873477     0.8824        0.015478       0.006899   \n",
       "5            LightGBMXT    0.871430     0.8792        0.032820       0.009035   \n",
       "6      RandomForestGini    0.859351     0.8612        0.171715       0.050751   \n",
       "7        NeuralNetTorch    0.859044     0.8584        0.021528       0.010361   \n",
       "8      RandomForestEntr    0.857611     0.8584        0.140409       0.049410   \n",
       "9       NeuralNetFastAI    0.856485     0.8636        0.070515       0.021800   \n",
       "10       ExtraTreesGini    0.853414     0.8528        0.153458       0.051717   \n",
       "11       ExtraTreesEntr    0.850650     0.8524        0.190824       0.048388   \n",
       "12       KNeighborsUnif    0.773467     0.7752        0.058189       0.026229   \n",
       "13       KNeighborsDist    0.762719     0.7660        0.084994       0.015142   \n",
       "\n",
       "     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0    0.661730                 0.038864                0.028366   \n",
       "1    3.062064                 0.001733                0.001742   \n",
       "2    3.251698                 0.009802                0.005365   \n",
       "3    0.836131                 0.033295                0.008739   \n",
       "4    0.343505                 0.015478                0.006899   \n",
       "5    0.671972                 0.032820                0.009035   \n",
       "6    0.588709                 0.171715                0.050751   \n",
       "7   16.629256                 0.021528                0.010361   \n",
       "8    0.598262                 0.140409                0.049410   \n",
       "9   15.249409                 0.070515                0.021800   \n",
       "10   0.538761                 0.153458                0.051717   \n",
       "11   0.515351                 0.190824                0.048388   \n",
       "12   0.038044                 0.058189                0.026229   \n",
       "13   0.033336                 0.084994                0.015142   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.661730            1       True         11  \n",
       "1            0.510682            2       True         14  \n",
       "2            3.251698            1       True          7  \n",
       "3            0.836131            1       True         13  \n",
       "4            0.343505            1       True          4  \n",
       "5            0.671972            1       True          3  \n",
       "6            0.588709            1       True          5  \n",
       "7           16.629256            1       True         12  \n",
       "8            0.598262            1       True          6  \n",
       "9           15.249409            1       True         10  \n",
       "10           0.538761            1       True          8  \n",
       "11           0.515351            1       True          9  \n",
       "12           0.038044            1       True          1  \n",
       "13           0.033336            1       True          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723fe3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_feather('/mnt/sda/wuyao/research/明达/data/train.feather')\n",
    "test=pd.read_feather('/mnt/sda/wuyao/research/明达/data/test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdde3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=['w_r_1',\n",
    " 'w_r_2',\n",
    " 'w_r_3',\n",
    " 'w_r_4',\n",
    " 'w_r_5',\n",
    " 'w_r_6',\n",
    " 'w_r_7',\n",
    " 'w_r_8',\n",
    " 'w_r_9',\n",
    " 'w_r_10',\n",
    " 'w_r_11',\n",
    " 'w_r_12',\n",
    " 'w_r_13',\n",
    " 'w_r_14',\n",
    " 'w_r_15',\n",
    " 'w_r_16',\n",
    " 'w_r_17',\n",
    " 'w_r_18',\n",
    " 'w_r_19',\n",
    " 'w_r_20',\n",
    " 'w_r_21',\n",
    " 'w_r_22',\n",
    " 'w_r_23',\n",
    " 'w_r_24',\n",
    " 'w_r_25',\n",
    " 'w_r_26',\n",
    " 'w_r_27',\n",
    " 'w_r_28',\n",
    " 'w_r_29',\n",
    " 'w_r_30',\n",
    " 'w_r_s_1',\n",
    " 'w_r_s_2',\n",
    " 'w_r_s_3',\n",
    " 'w_r_s_4',\n",
    " 'w_r_s_5',\n",
    " 'w_r_s_6',\n",
    " 'w_r_s_7',\n",
    " 'w_r_s_8',\n",
    " 'w_r_s_9',\n",
    " 'w_r_s_10',\n",
    " 'w_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6510cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231023_030100/\"\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231023_030100/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #96~20.04.1-Ubuntu SMP Thu Sep 21 13:23:37 UTC 2023\n",
      "Disk Space Avail:   7229.38 GB / 7937.30 GB (91.1%)\n",
      "Train Data Rows:    1762944\n",
      "Train Data Columns: 40\n",
      "Label Column: w_r\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.6915861021588608, -0.13854131105574716, -0.0, 0.01406)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    40132.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 564.14 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['w_r_s_1']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['w_r_s_1']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 39 | ['w_r_1', 'w_r_2', 'w_r_3', 'w_r_4', 'w_r_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 39 | ['w_r_1', 'w_r_2', 'w_r_3', 'w_r_4', 'w_r_5', ...]\n",
      "\t8.1s = Fit runtime\n",
      "\t39 features in original data used to generate 39 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 550.04 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 1745314, Val Rows: 17630\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 111.48s of the 111.48s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.980 GB out of 39.599 GB available memory (12.376%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.22 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f64bc212dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t-0.0149\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t10.53s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 96.93s of the 96.93s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.980 GB out of 39.592 GB available memory (12.378%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.22 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f64bc212dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t-0.0149\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t10.14s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 82.79s of the 82.79s of remaining time.\n",
      "\t-0.0138\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 63.03s of the 63.03s of remaining time.\n",
      "\t-0.0138\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 54.18s of the 54.18s of remaining time.\n",
      "\tWarning: Model is expected to require 12394.7s to train, which exceeds the maximum time limit of 54.2s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 111.48s of the -114.34s of remaining time.\n",
      "\t-0.0138\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 235.07s ... Best model: \"WeightedEnsemble_L2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231023_030100/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f64bf019e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f64bedf7790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBMXT   -0.014189  -0.013789        1.475051       0.036153  19.715186                 1.475051                0.036153          19.715186            1       True          3\n",
      "1  WeightedEnsemble_L2   -0.014189  -0.013789        1.478578       0.036419  19.807811                 0.003526                0.000266           0.092625            2       True          5\n",
      "2             LightGBM   -0.014194  -0.013804        0.493375       0.012507   8.835167                 0.493375                0.012507           8.835167            1       True          4\n",
      "3       KNeighborsUnif   -0.015186  -0.014872      309.231673      10.533901   3.890455               309.231673               10.533901           3.890455            1       True          1\n",
      "4       KNeighborsDist   -0.015189  -0.014865      304.368653      10.139804   3.888856               304.368653               10.139804           3.888856            1       True          2\n"
     ]
    }
   ],
   "source": [
    "v_y='w_r'\n",
    "predictor = TabularPredictor(label=v_y).fit(train[xx], time_limit=120)  # Fit models for 120s\n",
    "leaderboard = predictor.leaderboard(test[xx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13239ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.014189</td>\n",
       "      <td>-0.013789</td>\n",
       "      <td>1.475051</td>\n",
       "      <td>0.036153</td>\n",
       "      <td>19.715186</td>\n",
       "      <td>1.475051</td>\n",
       "      <td>0.036153</td>\n",
       "      <td>19.715186</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.014189</td>\n",
       "      <td>-0.013789</td>\n",
       "      <td>1.478578</td>\n",
       "      <td>0.036419</td>\n",
       "      <td>19.807811</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.092625</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.014194</td>\n",
       "      <td>-0.013804</td>\n",
       "      <td>0.493375</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>8.835167</td>\n",
       "      <td>0.493375</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>8.835167</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.015186</td>\n",
       "      <td>-0.014872</td>\n",
       "      <td>309.231673</td>\n",
       "      <td>10.533901</td>\n",
       "      <td>3.890455</td>\n",
       "      <td>309.231673</td>\n",
       "      <td>10.533901</td>\n",
       "      <td>3.890455</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.015189</td>\n",
       "      <td>-0.014865</td>\n",
       "      <td>304.368653</td>\n",
       "      <td>10.139804</td>\n",
       "      <td>3.888856</td>\n",
       "      <td>304.368653</td>\n",
       "      <td>10.139804</td>\n",
       "      <td>3.888856</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0           LightGBMXT   -0.014189  -0.013789        1.475051       0.036153   \n",
       "1  WeightedEnsemble_L2   -0.014189  -0.013789        1.478578       0.036419   \n",
       "2             LightGBM   -0.014194  -0.013804        0.493375       0.012507   \n",
       "3       KNeighborsUnif   -0.015186  -0.014872      309.231673      10.533901   \n",
       "4       KNeighborsDist   -0.015189  -0.014865      304.368653      10.139804   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  19.715186                 1.475051                0.036153   \n",
       "1  19.807811                 0.003526                0.000266   \n",
       "2   8.835167                 0.493375                0.012507   \n",
       "3   3.890455               309.231673               10.533901   \n",
       "4   3.888856               304.368653               10.139804   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          19.715186            1       True          3  \n",
       "1           0.092625            2       True          5  \n",
       "2           8.835167            1       True          4  \n",
       "3           3.890455            1       True          1  \n",
       "4           3.888856            1       True          2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2de739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test[xx])#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a09055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -0.001821\n",
       "1        -0.001225\n",
       "2        -0.000967\n",
       "3        -0.002653\n",
       "4        -0.002086\n",
       "            ...   \n",
       "755659    0.001565\n",
       "755660    0.001687\n",
       "755661   -0.000087\n",
       "755662    0.001237\n",
       "755663   -0.001497\n",
       "Name: w_r, Length: 755664, dtype: float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b57a18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -0.017118\n",
       "1         0.000676\n",
       "2        -0.002349\n",
       "3        -0.002116\n",
       "4        -0.010463\n",
       "            ...   \n",
       "755659    0.007863\n",
       "755660    0.006572\n",
       "755661    0.015878\n",
       "755662    0.010483\n",
       "755663   -0.003176\n",
       "Name: w_r, Length: 755664, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['w_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bbc08a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56092/3241204634.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  test.corr()['pred_all']['w_r']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10637249626388022"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_all']=y_pred\n",
    "test.corr()['pred_all']['w_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1b6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    " \n",
    "def evaluation(y_test, y_predict,n=363,p=100):\n",
    "    mae = mean_absolute_error(y_test, y_predict)\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    mape=(abs(y_predict -y_test)/ abs(y_test)).mean()\n",
    "    r_2=r2_score(y_test, y_predict)\n",
    "    \n",
    "    r2_adj=1-((1-r2_score(y_test,y_predict))*(n-1))/(n-p-1)\n",
    "    return mae, rmse, mape,r_2,r2_adj #mse\n",
    "df_eval=pd.DataFrame(columns=['MAE','RMSE','MAPE','R2','R2_adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd6978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009010066798748415,\n",
       " 0.014260966307739757,\n",
       " 1.3343376867600283,\n",
       " 0.0012562835444752674,\n",
       " 0.0012034135965538484]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score0=list(evaluation(test['w_r'],np.array(test['pred']),len(test),len(xx)-1))\n",
    "score0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e392119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_r_1',\n",
       " 'w_r_2',\n",
       " 'w_r_3',\n",
       " 'w_r_4',\n",
       " 'w_r_5',\n",
       " 'w_r_6',\n",
       " 'w_r_7',\n",
       " 'w_r_8',\n",
       " 'w_r_9',\n",
       " 'w_r_10',\n",
       " 'w_r_11',\n",
       " 'w_r_12',\n",
       " 'w_r_13',\n",
       " 'w_r_14',\n",
       " 'w_r_15',\n",
       " 'w_r_16',\n",
       " 'w_r_17',\n",
       " 'w_r_18',\n",
       " 'w_r_19',\n",
       " 'w_r_20',\n",
       " 'w_r_21',\n",
       " 'w_r_22',\n",
       " 'w_r_23',\n",
       " 'w_r_24',\n",
       " 'w_r_25',\n",
       " 'w_r_26',\n",
       " 'w_r_27',\n",
       " 'w_r_28',\n",
       " 'w_r_29',\n",
       " 'w_r_30',\n",
       " 'w_r_s_1',\n",
       " 'w_r_s_2',\n",
       " 'w_r_s_3',\n",
       " 'w_r_s_4',\n",
       " 'w_r_s_5',\n",
       " 'w_r_s_6',\n",
       " 'w_r_s_7',\n",
       " 'w_r_s_8',\n",
       " 'w_r_s_9',\n",
       " 'w_r_s_10',\n",
       " 'w_r']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1daf032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBMXT  -0.013789       0.036153  19.715186                0.036153          19.715186            1       True          3\n",
      "1  WeightedEnsemble_L2  -0.013789       0.036419  19.807811                0.000266           0.092625            2       True          5\n",
      "2             LightGBM  -0.013804       0.012507   8.835167                0.012507           8.835167            1       True          4\n",
      "3       KNeighborsDist  -0.014865      10.139804   3.888856               10.139804           3.888856            1       True          2\n",
      "4       KNeighborsUnif  -0.014872      10.533901   3.890455               10.533901           3.890455            1       True          1\n",
      "Number of models trained: 5\n",
      "Types of models trained:\n",
      "{'KNNModel', 'LGBModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 39 | ['w_r_1', 'w_r_2', 'w_r_3', 'w_r_4', 'w_r_5', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23fe72d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regression'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.problem_type# 查看预测类型，即回归还是分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bf2ed16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogluon.common.features.feature_metadata.FeatureMetadata at 0x7f65ecbc39d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_metadata# 数据标签列的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7055fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231025_134544/\"\n",
      "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231025_134544/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #96~20.04.1-Ubuntu SMP Thu Sep 21 13:23:37 UTC 2023\n",
      "Disk Space Avail:   7219.46 GB / 7937.30 GB (91.0%)\n",
      "Train Data Rows:    1762944\n",
      "Train Data Columns: 40\n",
      "Label Column: w_r\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.6915861021588608, -0.13854131105574716, -0.0, 0.01406)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11415.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 564.14 MB (4.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['w_r_s_1']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['w_r_s_1']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 39 | ['w_r_1', 'w_r_2', 'w_r_3', 'w_r_4', 'w_r_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 39 | ['w_r_1', 'w_r_2', 'w_r_3', 'w_r_4', 'w_r_5', ...]\n",
      "\t7.9s = Fit runtime\n",
      "\t39 features in original data used to generate 39 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 550.04 MB (4.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 34.45s of the 51.69s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 34.45s of the 51.69s of remaining time.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 34.45s of the 51.69s of remaining time.\n",
      "\tWarning: Exception caused RandomForestMSE_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 34.43s of the 51.67s of remaining time.\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 34.43s of the 51.67s of remaining time.\n",
      "\tWarning: Exception caused ExtraTreesMSE_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 34.43s of the 51.66s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 34.43s of the 51.66s of remaining time.\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 34.42s of the 51.66s of remaining time.\n",
      "\tMemory not enough to fit TabularNeuralNetTorchModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4.99s of the 22.23s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tstopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 818, in fit\n",
      "    kwargs = self.initialize(\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 69, in _initialize\n",
      "    super()._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 153, in _init_misc\n",
      "    child.initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 507, in initialize\n",
      "    self._initialize(**kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 526, in _initialize\n",
      "    self._init_misc(X=X, y=y, feature_metadata=feature_metadata, num_classes=num_classes, **kwargs)\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 543, in _init_misc\n",
      "    self.stopping_metric = self.params_aux.get(\"stopping_metric\", self._get_default_stopping_metric())\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1779, in _get_default_stopping_metric\n",
      "    stopping_metric = metrics.get_metric(stopping_metric, self.problem_type, \"stopping_metric\")\n",
      "  File \"/home/jiashu/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/metrics/__init__.py\", line 587, in get_metric\n",
      "    raise ValueError(\n",
      "ValueError: stopping_metric='log_loss' is not a valid metric for problem_type='regression'. Valid problem_types for this metric: ['binary', 'multiclass']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed 1/20 k-fold bagging repeats ...\n",
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "No base models to train on, skipping stack level 2...\n",
      "No base models to train on, skipping auxiliary stack level 3...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "AutoGluon did not successfully train any models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m  \u001b[38;5;66;03m# 设置模型最多等待时间60s\u001b[39;00m\n\u001b[1;32m      2\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 评定指标\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgood_quality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimize_for_deployment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m predictor\u001b[38;5;241m.\u001b[39mleaderboard(test_data, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/tabular/predictor/predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m     aux_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_weighted_ensemble\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlabeled_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_bag_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_bag_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_bag_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_bag_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bag_holdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bag_holdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_post_fit_vars()\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_fit(\n\u001b[1;32m   1006\u001b[0m     keep_only_best\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep_only_best\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1007\u001b[0m     refit_full\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit_full\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     infer_limit\u001b[38;5;241m=\u001b[39minfer_limit,\n\u001b[1;32m   1013\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/tabular/learner/abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearner is already fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_input(X\u001b[38;5;241m=\u001b[39mX, X_val\u001b[38;5;241m=\u001b[39mX_val, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/tabular/learner/default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39meval_metric\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m--> 157\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit_trainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_trainer(trainer\u001b[38;5;241m=\u001b[39mtrainer)\n\u001b[1;32m    171\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/tabular/trainer/auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m log_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m20\u001b[39m, log_str)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_multi_and_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py:2384\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2371\u001b[0m model_names_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_multi_levels(\n\u001b[1;32m   2372\u001b[0m     X,\n\u001b[1;32m   2373\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2381\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2382\u001b[0m )\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2384\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoGluon did not successfully train any models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_names_fit\n",
      "\u001b[0;31mValueError\u001b[0m: AutoGluon did not successfully train any models"
     ]
    }
   ],
   "source": [
    "time_limit = 60  # 设置模型最多等待时间60s\n",
    "metric = 'roc_auc'  # 评定指标\n",
    "predictor = TabularPredictor(v_y, eval_metric=metric).fit(train[xx], time_limit=time_limit,presets=['good_quality', 'optimize_for_deployment'])\n",
    "predictor.leaderboard(test_data, silent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a209f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py] *",
   "language": "python",
   "name": "conda-env-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
